{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP on songs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKhbXCrT7ONFCIY1Ne1L1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishik-00/Natural-Language-Processing/blob/master/NLP_on_songs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvI4df1CLW1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  tensorflow as  tf\n",
        "from tensorflow.keras.preprocessing.text import  Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiNL8Ehwv7gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open('/songs.txt').read()\n",
        "data = data.lower().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ultHMWS9wj1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VSo46Wwl7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ed33bf2-606c-43c3-feb8-962955258059"
      },
      "source": [
        "tokenizer.fit_on_texts(data)\n",
        "total_words = len(tokenizer.word_index)+ 1\n",
        "total_words"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FsvzctLxCXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in data:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0] # this [line] is used to do word by word, and [0] isto get rid of the  nested list\n",
        "  for i in range(1, len(token_list)):\n",
        "    sequence = token_list[:i+1]\n",
        "    input_sequences.append(sequence)\n",
        "\n",
        "# pad sequences\n",
        "max_len = max(len(x) for x in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding = 'pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puCKn70Vzefi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a683e2bb-7fd1-4dde-a20b-c3e6c87036d4"
      },
      "source": [
        "input_sequences\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   4,  51],\n",
              "       [  0,   0,   0, ...,   4,  51,  17],\n",
              "       [  0,   0,   0, ...,  51,  17,   7],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  14,  99, 282],\n",
              "       [  0,   0,   0, ...,  99, 282,  31],\n",
              "       [  0,   0,   0, ..., 282,  31,   1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ1zRFOe1z1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "label = input_sequences[:, -1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TIF_1-o24fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(label, num_classes = total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkLGsbTq3fGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "425553d4-fb6c-45ce-bd7e-5e8025a6f460"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(total_words, 64, input_length = max_len-1))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)))\n",
        "model.add(tf.keras.layers.Dense(total_words, activation = 'softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'] ,optimizer = 'adam')\n",
        "history = model.fit(xs, y_train, epochs = 200, verbose = 1)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.6094 - accuracy: 0.0479\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.1738 - accuracy: 0.0429\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.8305 - accuracy: 0.0449\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.7689 - accuracy: 0.0509\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.7198 - accuracy: 0.0689\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.6616 - accuracy: 0.0888\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.5984 - accuracy: 0.0758\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.5190 - accuracy: 0.0938\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.4215 - accuracy: 0.1078\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.3173 - accuracy: 0.1228\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.2211 - accuracy: 0.1198\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.1205 - accuracy: 0.1417\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.0211 - accuracy: 0.1487\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.9347 - accuracy: 0.1557\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.8516 - accuracy: 0.1657\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.7646 - accuracy: 0.1756\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.6857 - accuracy: 0.2066\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.6043 - accuracy: 0.2206\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.5283 - accuracy: 0.2485\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.4515 - accuracy: 0.2615\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.3843 - accuracy: 0.2764\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.3103 - accuracy: 0.3094\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.2393 - accuracy: 0.3034\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.1697 - accuracy: 0.3273\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.0930 - accuracy: 0.3493\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.0350 - accuracy: 0.3723\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.9881 - accuracy: 0.3693\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.9071 - accuracy: 0.3892\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.8345 - accuracy: 0.4291\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.7813 - accuracy: 0.4232\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.7221 - accuracy: 0.4162\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.6582 - accuracy: 0.4451\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.5958 - accuracy: 0.4760\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.5415 - accuracy: 0.4860\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.4952 - accuracy: 0.4840\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.4461 - accuracy: 0.5030\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.3982 - accuracy: 0.5230\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.3529 - accuracy: 0.5250\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.3131 - accuracy: 0.5379\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.2750 - accuracy: 0.5319\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.2217 - accuracy: 0.5589\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.1851 - accuracy: 0.5569\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.1593 - accuracy: 0.5669\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.1056 - accuracy: 0.5699\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.0738 - accuracy: 0.5858\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.0301 - accuracy: 0.5848\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.9848 - accuracy: 0.6008\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.9393 - accuracy: 0.6138\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.9206 - accuracy: 0.6098\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.9450 - accuracy: 0.6008\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.9006 - accuracy: 0.6058\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.8672 - accuracy: 0.6098\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.8886 - accuracy: 0.6038\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.8125 - accuracy: 0.6257\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.7731 - accuracy: 0.6257\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.7216 - accuracy: 0.6467\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.6846 - accuracy: 0.6597\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.6461 - accuracy: 0.6677\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.6169 - accuracy: 0.6786\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5960 - accuracy: 0.6786\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5845 - accuracy: 0.6756\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5473 - accuracy: 0.6886\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5274 - accuracy: 0.6876\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5030 - accuracy: 0.6996\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4885 - accuracy: 0.6976\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4631 - accuracy: 0.6956\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4444 - accuracy: 0.6986\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4680 - accuracy: 0.6926\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4502 - accuracy: 0.6966\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4017 - accuracy: 0.7106\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.3632 - accuracy: 0.7216\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3772 - accuracy: 0.7335\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3469 - accuracy: 0.7255\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.3040 - accuracy: 0.7385\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.2690 - accuracy: 0.7505\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.2499 - accuracy: 0.7565\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.2260 - accuracy: 0.7645\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.2056 - accuracy: 0.7685\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1880 - accuracy: 0.7715\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1668 - accuracy: 0.7725\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1545 - accuracy: 0.7864\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1409 - accuracy: 0.7814\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1346 - accuracy: 0.7784\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1185 - accuracy: 0.7884\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1042 - accuracy: 0.7854\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1312 - accuracy: 0.7834\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.1247 - accuracy: 0.7764\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1102 - accuracy: 0.7784\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0708 - accuracy: 0.7974\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0580 - accuracy: 0.8004\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0540 - accuracy: 0.8064\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0229 - accuracy: 0.8054\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.8074\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9866 - accuracy: 0.8194\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9657 - accuracy: 0.8273\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9551 - accuracy: 0.8224\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9335 - accuracy: 0.8303\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9331 - accuracy: 0.8333\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9161 - accuracy: 0.8363\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9067 - accuracy: 0.8383\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8890 - accuracy: 0.8403\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.8723 - accuracy: 0.8483\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.8569 - accuracy: 0.8563\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.8397 - accuracy: 0.8573\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.8290 - accuracy: 0.8583\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8475 - accuracy: 0.8543\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.8265 - accuracy: 0.8603\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.8086 - accuracy: 0.8653\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7861 - accuracy: 0.8683\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7768 - accuracy: 0.8733\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.7700 - accuracy: 0.8703\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7613 - accuracy: 0.8683\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7475 - accuracy: 0.8703\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7465 - accuracy: 0.8743\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7330 - accuracy: 0.8752\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.7346 - accuracy: 0.8762\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7174 - accuracy: 0.8733\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7053 - accuracy: 0.8792\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6947 - accuracy: 0.8802\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6879 - accuracy: 0.8862\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6715 - accuracy: 0.8832\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6617 - accuracy: 0.8862\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6861 - accuracy: 0.8782\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6708 - accuracy: 0.8812\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6662 - accuracy: 0.8872\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6483 - accuracy: 0.8852\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6459 - accuracy: 0.8832\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.8872\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.7050 - accuracy: 0.8663\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6753 - accuracy: 0.8743\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 0.8743\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6560 - accuracy: 0.8713\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6357 - accuracy: 0.8822\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6018 - accuracy: 0.8902\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.8882\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5984 - accuracy: 0.8882\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5754 - accuracy: 0.8932\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.8922\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5687 - accuracy: 0.8922\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5755 - accuracy: 0.8922\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5754 - accuracy: 0.8902\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5832 - accuracy: 0.8822\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6318 - accuracy: 0.8723\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5773 - accuracy: 0.8912\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5666 - accuracy: 0.8822\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5368 - accuracy: 0.8952\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5203 - accuracy: 0.8982\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5170 - accuracy: 0.9002\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5005 - accuracy: 0.9002\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4945 - accuracy: 0.9022\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.9042\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4895 - accuracy: 0.9032\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4815 - accuracy: 0.9082\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4707 - accuracy: 0.9102\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4671 - accuracy: 0.9092\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4785 - accuracy: 0.9062\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4716 - accuracy: 0.9062\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4563 - accuracy: 0.9082\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4480 - accuracy: 0.9132\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4415 - accuracy: 0.9132\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4366 - accuracy: 0.9182\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4316 - accuracy: 0.9162\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4234 - accuracy: 0.9162\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4209 - accuracy: 0.9202\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4182 - accuracy: 0.9162\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4120 - accuracy: 0.9212\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4080 - accuracy: 0.9162\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4039 - accuracy: 0.9222\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.4011 - accuracy: 0.9232\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3959 - accuracy: 0.9212\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.9242\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3867 - accuracy: 0.9271\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3839 - accuracy: 0.9251\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.9281\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3852 - accuracy: 0.9242\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3833 - accuracy: 0.9232\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3756 - accuracy: 0.9251\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3719 - accuracy: 0.9222\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3678 - accuracy: 0.9242\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3688 - accuracy: 0.9212\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3613 - accuracy: 0.9281\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3834 - accuracy: 0.9162\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3840 - accuracy: 0.9212\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3728 - accuracy: 0.9222\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3556 - accuracy: 0.9271\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3489 - accuracy: 0.9291\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3483 - accuracy: 0.9271\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.9261\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3418 - accuracy: 0.9281\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3375 - accuracy: 0.9281\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3341 - accuracy: 0.9301\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.9291\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.3309 - accuracy: 0.9291\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3284 - accuracy: 0.9291\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3259 - accuracy: 0.9311\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.9331\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3199 - accuracy: 0.9301\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3157 - accuracy: 0.9321\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3145 - accuracy: 0.9331\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3250 - accuracy: 0.9271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jt7gA9D37LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_graph(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel(string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9HOu-_c6CD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "005ea430-87f1-4413-e5f8-99635a7b58e0"
      },
      "source": [
        "plot_graph(history, 'accuracy')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIEJ_aDA7oL2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "db8e79ac-1fa9-432b-9397-26d8a1b6039f"
      },
      "source": [
        "text = 'I want my love'\n",
        "next_words = 50\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen = max_len - 1, padding = 'pre')\n",
        "  predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "  output_word = ''\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  text += \" \" + output_word\n",
        "print(text)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want my love with your baby you like i too new now bedsheets room time room do heart lover too much lover lover lover at the shots shots feel it it room room room room do shape a sour shots can lover table bag it too her share her home friends hand sour\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyyrM7J6-bmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}